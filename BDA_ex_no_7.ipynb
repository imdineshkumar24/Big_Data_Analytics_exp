{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/PawVPa/VUWb7MRUVy0R4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imdineshkumar24/Big_Data_Analytics_exp/blob/main/BDA_ex_no_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9uInldmrb9f",
        "outputId": "c3f9a15f-34d4-4cf8-a744-06f216e12cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=a17b53b5a7851b53041760b42d0a288f0c21f246d2a35ae7937c360b93f7141a\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[1]\").appName(\"BDA_ex_no_7\").getOrCreate()"
      ],
      "metadata": {
        "id": "UYe9U2r_rkE5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "[\"21ADR001\", \"Dinesh\", \"AI\",88, 'Anand'],\n",
        "[\"21CSR55\", \"Suganth\", \"CSE\", 90, 'Divaker'],\n",
        "[\"21CSR76\", \"Vetri\",  \"CSE\", 87, 'Prakash'],\n",
        "[\"21ADR072\", \"Dhanush\",\"AI\", 98, 'Prakash'],\n",
        "[\"21ITR005\", \"Yaswin\",\"IT\",68, 'Anand'],\n",
        "[\"21MTR002\", \"Srihari\",\"MTS\", 88, 'Anand'],\n",
        "[\"21ITR002\", \"Deepak\",\"IT\", 88, 'Divaker'],\n",
        "[\"21MTR002\", \"Nithish\",\"MTS\", 86, 'Prakash']\n",
        "]\n",
        "columns = ['ID','name','dept','subject_1','Advisor']\n",
        "df = spark.createDataFrame(data,columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmECmzJArpqo",
        "outputId": "defda635-da80-48f7-fb6a-b5fb3101f505"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+\n",
            "|      ID|   name|dept|subject_1|Advisor|\n",
            "+--------+-------+----+---------+-------+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|\n",
            "|21MTR002|Srihari| MTS|       88|  Anand|\n",
            "|21ITR002| Deepak|  IT|       88|Divaker|\n",
            "|21MTR002|Nithish| MTS|       86|Prakash|\n",
            "+--------+-------+----+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsaLuTpstnLg",
        "outputId": "ffe12463-834d-4c24-8b69-50c0808bdaae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- ID: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- dept: string (nullable = true)\n",
            " |-- subject_1: long (nullable = true)\n",
            " |-- subject_2: long (nullable = true)\n",
            " |-- Advisor: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec = Window.partitionBy(\"dept\").orderBy(\"subject_1\")\n",
        "df.withColumn(\"row_number\",row_number().over(windowSpec)).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZRca5qzttQH",
        "outputId": "af7d47ad-219d-4a2e-fedf-188fe71c47e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+----------+\n",
            "|ID      |name   |dept|subject_1|Advisor|row_number|\n",
            "+--------+-------+----+---------+-------+----------+\n",
            "|21ADR001|Dinesh |AI  |88       |Anand  |1         |\n",
            "|21ADR072|Dhanush|AI  |98       |Prakash|2         |\n",
            "|21CSR76 |Vetri  |CSE |87       |Prakash|1         |\n",
            "|21CSR55 |Suganth|CSE |90       |Divaker|2         |\n",
            "|21ITR005|Yaswin |IT  |68       |Anand  |1         |\n",
            "|21ITR002|Deepak |IT  |88       |Divaker|2         |\n",
            "|21MTR002|Nithish|MTS |86       |Prakash|1         |\n",
            "|21MTR002|Srihari|MTS |88       |Anand  |2         |\n",
            "+--------+-------+----+---------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank\n",
        "df.withColumn(\"rank\",rank().over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofQLeF8WuND3",
        "outputId": "38c80e4c-5ecf-4937-b345-33ae578bd474"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+----+\n",
            "|      ID|   name|dept|subject_1|Advisor|rank|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|   1|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|   2|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|   1|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|   2|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|   1|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        "df.withColumn(\"dense_rank\",dense_rank().over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ZB30aKuZfF",
        "outputId": "c084505b-dcf6-4580-a3dc-fe7dfb3e7c17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+----------+\n",
            "|      ID|   name|dept|subject_1|Advisor|dense_rank|\n",
            "+--------+-------+----+---------+-------+----------+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|         1|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|         2|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|         1|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|         2|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|         1|\n",
            "+--------+-------+----+---------+-------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import percent_rank\n",
        "df.withColumn(\"percent_rank\",percent_rank().over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urlL3cgtucpG",
        "outputId": "83cd0b3c-218d-42b4-e60b-bb4b38520581"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+------------+\n",
            "|      ID|   name|dept|subject_1|Advisor|percent_rank|\n",
            "+--------+-------+----+---------+-------+------------+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|         0.0|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|         1.0|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|         0.0|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|         1.0|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|         0.0|\n",
            "+--------+-------+----+---------+-------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import ntile\n",
        "df.withColumn(\"ntile\",ntile(2).over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-SY3M73un9G",
        "outputId": "506c2443-619c-47c6-e27e-513da94137a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+-----+\n",
            "|      ID|   name|dept|subject_1|Advisor|ntile|\n",
            "+--------+-------+----+---------+-------+-----+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|    1|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|    2|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|    1|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|    2|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|    1|\n",
            "+--------+-------+----+---------+-------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import cume_dist\n",
        "df.withColumn(\"cume_dist\",cume_dist().over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQMWyCQWufSl",
        "outputId": "ea5e6328-8f68-48d8-ee30-5e7fa0a8455e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+---------+\n",
            "|      ID|   name|dept|subject_1|Advisor|cume_dist|\n",
            "+--------+-------+----+---------+-------+---------+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|      0.5|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|      1.0|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|      0.5|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|      1.0|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|      0.5|\n",
            "+--------+-------+----+---------+-------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag\n",
        "df.withColumn(\"lag\",lag(\"subject_1\",2).over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THRsiZsFurL1",
        "outputId": "7de76f04-f227-44f0-be82-054ed8353996"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+----+\n",
            "|      ID|   name|dept|subject_1|Advisor| lag|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|NULL|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|NULL|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|NULL|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|NULL|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|NULL|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead\n",
        "df.withColumn(\"lead\",lead(\"subject_1\",2).over(windowSpec)).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAQql2LXuyeN",
        "outputId": "abc68968-68ef-42b7-d376-41b34ae52448"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------+----+---------+-------+----+\n",
            "|      ID|   name|dept|subject_1|Advisor|lead|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "|21ADR001| Dinesh|  AI|       88|  Anand|NULL|\n",
            "|21ADR072|Dhanush|  AI|       98|Prakash|NULL|\n",
            "| 21CSR76|  Vetri| CSE|       87|Prakash|NULL|\n",
            "| 21CSR55|Suganth| CSE|       90|Divaker|NULL|\n",
            "|21ITR005| Yaswin|  IT|       68|  Anand|NULL|\n",
            "+--------+-------+----+---------+-------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, avg, sum, min, max, row_number"
      ],
      "metadata": {
        "id": "G4I3WHhPu9nA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpecAgg = Window.partitionBy(\"dept\")\n",
        "windowSpec = Window.partitionBy(\"dept\").orderBy(\"subject_1\")"
      ],
      "metadata": {
        "id": "EDJVeIPlvC8Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"row\", row_number().over(windowSpec)) \\\n",
        "  .withColumn(\"avg\", avg(col(\"subject_1\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"sum\", sum(col(\"subject_1\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"min\", min(col(\"subject_1\")).over(windowSpecAgg)) \\\n",
        "  .withColumn(\"max\", max(col(\"subject_1\")).over(windowSpecAgg)) \\\n",
        "  .where(col(\"row\") == 1).select(\"dept\", \"avg\", \"sum\", \"min\", \"max\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96wkGn4JvLv9",
        "outputId": "a7790f8d-faee-4cbd-d48a-969d2147d1e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+---+---+---+\n",
            "|dept| avg|sum|min|max|\n",
            "+----+----+---+---+---+\n",
            "|  AI|93.0|186| 88| 98|\n",
            "| CSE|88.5|177| 87| 90|\n",
            "|  IT|78.0|156| 68| 88|\n",
            "| MTS|87.0|174| 86| 88|\n",
            "+----+----+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RNrXpHKNvTc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}