{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb678sW/MtzPUpJMqACw3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imdineshkumar24/Big_Data_Analytics_exp/blob/main/BDA_ex_no_4a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27-XUvzPVv8B",
        "outputId": "7ccd6c6a-3f7d-4cbd-b8f0-84754e01ca47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=eca1b81a62a3cf0bb03a66c691150fdea7e022928507067066d34d39a75a722d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
      ],
      "metadata": {
        "id": "IUZQXP1dXOVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv(\"/content/IPL Player Stats - 2016 till 2019 - IPL Player Stats - 2016 till 2019.csv\",header=True)\n",
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wg8AU5HXSK3",
        "outputId": "d6ad77b6-22c5-49b8-ad45-a8f719d0c4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIB0l3KFh2xQ",
        "outputId": "22e705dd-e30d-409d-cab3-288df4ece9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------+----------+-------+---------------+-------+------------+-------------+---------------+-----------+-------------------+---+---+---+---+---+---------------+------------+--------------+-------------+-------------+--------------------+---------------+--------------------+-------------------+------------------+------------------+-------------+--------------+\n",
            "|            Team|       Player|Tournament|Matches|Batting Innings|Not Out|Runds Scored|Highest Score|Batting Average|Balls Faced|Batting Strike Rate|100| 50|  0| 4s| 6s|Bowling Innings|Overs Bowled|Maidens Bowled|Runs Conceded|Wickets Taken|Best Bowling Figures|Bowling Average|Bowling Economy Rate|Bowling Strike Rate|4+ Innings Wickets|5+ Innings Wickets|Catches Taken|Stumpings Made|\n",
            "+----------------+-------------+----------+-------+---------------+-------+------------+-------------+---------------+-----------+-------------------+---+---+---+---+---+---------------+------------+--------------+-------------+-------------+--------------------+---------------+--------------------+-------------------+------------------+------------------+-------------+--------------+\n",
            "|Delhi Daredevils|    CH Morris|  IPL 2016|     12|              7|      4|         195|          82*|             65|        109|             178.89|  0|  1|  1| 15| 12|             12|          44|             0|          308|           13|                2/30|          23.69|                   7|               20.3|                 0|                 0|            8|             0|\n",
            "|Delhi Daredevils|    CH Morris|  IPL 2017|      9|              9|      4|         154|          52*|           30.8|         94|             163.82|  0|  1|  0| 15|  6|              9|          31|             0|          240|           12|                4/26|             20|                7.74|               15.5|                 1|                 0|            5|             0|\n",
            "|Delhi Daredevils|    CH Morris|  IPL 2018|      4|              4|      3|          46|          27*|             46|         26|             176.92|  0|  0|  0|  3|  2|              4|          14|             0|          143|            3|                2/41|          47.66|               10.21|                 28|                 0|                 0|            2|             0|\n",
            "|Delhi Daredevils|    JP Duminy|  IPL 2016|     10|              8|      3|         191|          49*|           38.2|        156|             122.43|  0|  0|  0| 13|  3|              5|           7|             0|           55|            2|                 1/4|           27.5|                7.85|                 21|                 0|                 0|            3|             0|\n",
            "|Delhi Daredevils|    Q de Kock|  IPL 2016|     13|             13|      1|         445|          108|          37.08|        327|             136.08|  1|  3|  0| 52| 13|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            2|             2|\n",
            "|Delhi Daredevils|      KK Nair|  IPL 2016|     14|             12|      2|         357|          83*|           35.7|        297|              120.2|  0|  3|  0| 40|  6|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            3|             0|\n",
            "|Delhi Daredevils|      KK Nair|  IPL 2017|     14|             13|      0|         281|           64|          21.61|        226|             124.33|  0|  1|  1| 39|  6|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            2|             0|\n",
            "|Delhi Daredevils|       P Negi|  IPL 2016|      8|              6|      4|          57|          19*|           28.5|         59|              96.61|  0|  0|  0|  2|  3|              5|           9|             0|           84|            1|                1/19|             84|                9.33|                 54|                 0|                 0|            2|             0|\n",
            "|Delhi Daredevils|    SV Samson|  IPL 2016|     14|             14|      3|         291|           60|          26.45|        259|             112.35|  0|  1|  0| 20|  8|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            3|             1|\n",
            "|Delhi Daredevils|    SV Samson|  IPL 2017|     14|             14|      0|         386|          102|          27.57|        273|             141.39|  1|  2|  2| 32| 19|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            4|             0|\n",
            "|Delhi Daredevils|      RR Pant|  IPL 2016|     10|             10|      2|         198|           69|          24.75|        152|             130.26|  0|  1|  0| 19|  6|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            3|             0|\n",
            "|Delhi Daredevils|      RR Pant|  IPL 2017|     14|             14|      0|         366|           97|          26.14|        221|             165.61|  0|  2|  3| 28| 24|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            8|             3|\n",
            "|Delhi Daredevils|      RR Pant|  IPL 2018|     14|             14|      1|         684|         128*|          52.61|        394|              173.6|  1|  5|  1| 68| 37|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            4|             2|\n",
            "|Delhi Daredevils|  SW Billings|  IPL 2016|      5|              4|      0|          88|           54|             22|         64|              137.5|  0|  1|  0|  4|  4|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            3|             0|\n",
            "|Delhi Daredevils|  SW Billings|  IPL 2017|      6|              6|      0|         138|           55|             23|        104|             132.69|  0|  1|  1| 19|  1|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            4|             0|\n",
            "|Delhi Daredevils|CR Brathwaite|  IPL 2016|      8|              6|      0|          83|           34|          13.83|         38|             218.42|  0|  0|  0|  6|  8|              8|        23.1|             0|          189|            7|                3/47|             27|                8.15|               19.8|                 0|                 0|            3|             0|\n",
            "|Delhi Daredevils|CR Brathwaite|  IPL 2017|      2|              2|      0|          12|           11|              6|         15|                 80|  0|  0|  0|  2|  0|              2|           6|             0|           67|            1|                1/38|             67|               11.16|                 36|                 0|                 0|            0|             0|\n",
            "|Delhi Daredevils|   MA Agarwal|  IPL 2016|      3|              3|      0|          27|           10|              9|         25|                108|  0|  0|  0|  3|  1|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            0|             0|\n",
            "|Delhi Daredevils|      SS Iyer|  IPL 2016|      6|              6|      0|          30|           19|              5|         43|              69.76|  0|  0|  3|  2|  1|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            4|             0|\n",
            "|Delhi Daredevils|      SS Iyer|  IPL 2017|     12|             12|      2|         338|           96|           33.8|        243|             139.09|  0|  2|  0| 36| 10|              -|           -|             -|            -|            -|                   -|              -|                   -|                  -|                 -|                 -|            3|             0|\n",
            "+----------------+-------------+----------+-------+---------------+-------+------------+-------------+---------------+-----------+-------------------+---+---+---+---+---+---------------+------------+--------------+-------------+-------------+--------------------+---------------+--------------------+-------------------+------------------+------------------+-------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df['Team'],df['Runds Scored']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8XkTakqZS74",
        "outputId": "baf0a84a-83c2-414f-84f8-0ca48e5cfbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------+\n",
            "|            Team|Runds Scored|\n",
            "+----------------+------------+\n",
            "|Delhi Daredevils|         195|\n",
            "|Delhi Daredevils|         154|\n",
            "|Delhi Daredevils|          46|\n",
            "|Delhi Daredevils|         191|\n",
            "|Delhi Daredevils|         445|\n",
            "|Delhi Daredevils|         357|\n",
            "|Delhi Daredevils|         281|\n",
            "|Delhi Daredevils|          57|\n",
            "|Delhi Daredevils|         291|\n",
            "|Delhi Daredevils|         386|\n",
            "|Delhi Daredevils|         198|\n",
            "|Delhi Daredevils|         366|\n",
            "|Delhi Daredevils|         684|\n",
            "|Delhi Daredevils|          88|\n",
            "|Delhi Daredevils|         138|\n",
            "|Delhi Daredevils|          83|\n",
            "|Delhi Daredevils|          12|\n",
            "|Delhi Daredevils|          27|\n",
            "|Delhi Daredevils|          30|\n",
            "|Delhi Daredevils|         338|\n",
            "+----------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "dfs=spark.read.csv(\"/content/sample_csv_file - sample_csv_file.csv\")\n",
        "print(\"The input csv file is:\")\n",
        "dfs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AGUgy3oZmX_",
        "outputId": "646b4018-a57c-42d7-ca38-be9a86fc3825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input csv file is:\n",
            "+-------+-----+-------+---------+\n",
            "|    _c0|  _c1|    _c2|      _c3|\n",
            "+-------+-----+-------+---------+\n",
            "|   Name|Maths|Physics|Chemistry|\n",
            "| Aditya|   45|     89|        1|\n",
            "|  Chris|   86|     85|        2|\n",
            "|   Joel| null|     85|        3|\n",
            "|Katrina|   49|     47|        4|\n",
            "| Agatha|   76|     89|        5|\n",
            "|    Sam|   76|     98|        6|\n",
            "+-------+-----+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfs.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB87qIPvZxju",
        "outputId": "d7508511-45f8-4adb-e2ce-11baf8d2e026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('_c0', 'string'), ('_c1', 'string'), ('_c2', 'string'), ('_c3', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "list_of_cols=[StructField(\"Name\",StringType(),True),\n",
        "             StructField(\"Maths\",IntegerType(),True),\n",
        "             StructField(\"Physics\",IntegerType(),True),\n",
        "             StructField(\"Chemistry\",IntegerType(),True)]\n",
        "schema=StructType(list_of_cols)\n",
        "dfs=spark.read.csv(\"/content/sample_csv_file - sample_csv_file.csv\",header=True,schema=schema)\n",
        "print(\"The input csv file is:\")\n",
        "dfs.show()\n",
        "print(\"The data type of columns is:\")\n",
        "print(dfs.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQb2lqxsaFme",
        "outputId": "8ae7f531-72df-4a78-c800-5ec4e78df6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input csv file is:\n",
            "+-------+-----+-------+---------+\n",
            "|   Name|Maths|Physics|Chemistry|\n",
            "+-------+-----+-------+---------+\n",
            "| Aditya|   45|     89|        1|\n",
            "|  Chris|   86|     85|        2|\n",
            "|   Joel| null|     85|        3|\n",
            "|Katrina|   49|     47|        4|\n",
            "| Agatha|   76|     89|        5|\n",
            "|    Sam|   76|     98|        6|\n",
            "+-------+-----+-------+---------+\n",
            "\n",
            "The data type of columns is:\n",
            "[('Name', 'string'), ('Maths', 'int'), ('Physics', 'int'), ('Chemistry', 'int')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs=spark.read.csv(\"/content/demo_file - demo_file.csv\",header=True,inferSchema=True, sep=\"|\")\n",
        "print(\"The input csv file is:\")\n",
        "dfs.show()\n",
        "print(\"The data type of columns is:\")\n",
        "print(dfs.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1ujUlT2aYfl",
        "outputId": "4d60877e-817d-4bc4-9207-422c72abe87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input csv file is:\n",
            "+------+----+--------+-----+\n",
            "|  Name|Roll|Language|Extra|\n",
            "+------+----+--------+-----+\n",
            "|Aditya|   1|  Python|   11|\n",
            "|   Sam|   2|    Java|   12|\n",
            "| Chris|   3|  Python|   13|\n",
            "|   Joe|   8|    Java|   14|\n",
            "+------+----+--------+-----+\n",
            "\n",
            "The data type of columns is:\n",
            "[('Name', 'string'), ('Roll', 'int'), ('Language', 'string'), ('Extra', 'int')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs=spark.read.csv([\"/content/student_data2 - student_data2.csv\"],header=True,inferSchema=True, sep=\"|\")\n",
        "print(\"The input csv files are:\")\n",
        "dfs.show()\n",
        "print(\"The data type of columns is:\")\n",
        "print(dfs.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpu17fTlalKV",
        "outputId": "93a1b91f-0ca0-48d3-d9ac-a26258ad7e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The input csv files are:\n",
            "+------+----+----------+-----+-----+\n",
            "|  Name|Roll|  Language|Extra|Grade|\n",
            "+------+----+----------+-----+-----+\n",
            "|Aditya|   1|    Python|   11|    A|\n",
            "|   Sam|   2|      Java|   12|    A|\n",
            "| Chris|   3|       C++|   13|   A+|\n",
            "|  Joel|   4|TypeScript|   14|   A+|\n",
            "+------+----+----------+-----+-----+\n",
            "\n",
            "The data type of columns is:\n",
            "[('Name', 'string'), ('Roll', 'int'), ('Language', 'string'), ('Extra', 'int'), ('Grade', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.filter(\"Language != 'C#'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZxV4N4gcQfd",
        "outputId": "819c2aa3-b44e-4e2c-c843-56517d198606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+-----+-----+\n",
            "|  Name|Roll|  Language|Extra|Grade|\n",
            "+------+----+----------+-----+-----+\n",
            "|Aditya|   1|    Python|   11|    A|\n",
            "|   Sam|   2|      Java|   12|    A|\n",
            "| Chris|   3|       C++|   13|   A+|\n",
            "|  Joel|   4|TypeScript|   14|   A+|\n",
            "+------+----+----------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs1=dfs.groupBy(\"Language\").min(\"Extra\")\n",
        "dfs1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rIr9zCGcSL7",
        "outputId": "549626b0-123f-40f6-eb49-c023d3df7087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|  Language|min(Extra)|\n",
            "+----------+----------+\n",
            "|       C++|        13|\n",
            "|TypeScript|        14|\n",
            "|    Python|        11|\n",
            "|      Java|        12|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs1.write.csv(\"result.csv\")"
      ],
      "metadata": {
        "id": "5ooEvIdQcgZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.write.format(\"csv\").mode('overwrite').save(\"/content/result.csv\")"
      ],
      "metadata": {
        "id": "mlMAro_ndU_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = spark.read.text(\"/content/data.txt\")\n",
        "type(df2)\n",
        "\n",
        "df2.show(truncate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itc91nOldg1z",
        "outputId": "5ec68bec-8654-47c3-909c-77ab0b842750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|deer,beer,river,c...|\n",
            "|java,trust,read,w...|\n",
            "|               c,c++|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "df3=spark.read.json(\"/content/sample_jsondata.json\",multiLine=True)\n",
        "type(df3)\n",
        "print(df3.printSchema())\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TPYm1_8duKb",
        "outputId": "064a2d2c-e6b5-4de3-872f-1142b22b37a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Address: struct (nullable = true)\n",
            " |    |-- Permanent address: string (nullable = true)\n",
            " |    |-- current Address: string (nullable = true)\n",
            " |-- Boolean: boolean (nullable = true)\n",
            " |-- Mobile: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Pets: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "None\n",
            "+---------+-------+--------+----+----------+\n",
            "|  Address|Boolean|  Mobile|Name|      Pets|\n",
            "+---------+-------+--------+----+----------+\n",
            "|{USA, AU}|   true|12345678|Test|[Dog, cat]|\n",
            "+---------+-------+--------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbClXREReS2D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}